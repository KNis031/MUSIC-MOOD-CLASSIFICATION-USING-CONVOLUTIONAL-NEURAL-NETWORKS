# MUSIC MOOD CLASSIFICATION USING CONVOLUTIONAL NEURAL NETWORKS

By Elliot Remmer & Karl Simu

## Introduction

TBA

## Structure

Most of the files in this repo comes from the [MTG-jamendo Dataset repo](https://github.com/MTG/mtg-jamendo-dataset). While some folders & files have been removed in this version, many are kept for structure & transperency resons. The old README is found under old-readme/README.md

The models can be found in:

* scripts/baseline/fcn5.py
* scripts/baseline/fcn6.py
* scripts/baseline/fcn7.py

All scripts written or modified by us:
* scripts/baseline/fcn5.py
* scripts/baseline/fcn6.py
* scripts/baseline/fcn7.py
* scripts/baseline/data_loader.py
* scripts/baseline/get_npy.py
* scripts/baseline/solver.py
* scripts/specplot.py
* AUC-Loss-plots/plot.py


## Dataset

> Bogdanov, D., Won M., Tovstogan P., Porter A., & Serra X. (2019).  [The MTG-Jamendo Dataset for Automatic Music Tagging](https://hdl.handle.net/10230/42015). Machine Learning for Music Discovery Workshop, International Conference on Machine Learning (ICML 2019).


## License

* The code in this repository is licensed under [Apache 2.0](LICENSE) 
* The metadata is licensed under a [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/).
* The audio files are licensed under Creative Commons licenses, see individual licenses for details in `audio_licenses.txt`.

## Acknowledgments

2019 Music Technology Group For providing the dataset and additional scripts
